#!/usr/bin/env python3
"""
æ•°æ®ç”Ÿæˆè„šæœ¬ - ç”Ÿæˆæš–ç”·å›å¤æ•°æ®é›†
ä»åŸå§‹parquetæ•°æ®é›†ç”Ÿæˆæ–°çš„æ•°æ®ï¼Œè°ƒç”¨vLLM APIç”Ÿæˆæš–ç”·é£æ ¼çš„å›å¤

python generate_sunshine_boy_data.py --num 20 --start 5 --overwrite
"""

import pandas as pd
import requests
import json
import argparse
import os
import base64
import hashlib
import shutil
from pathlib import Path
from tqdm import tqdm
from PIL import Image
from io import BytesIO
import time
import re
from concurrent.futures import ProcessPoolExecutor, as_completed

class SunshineBoyDataGenerator:
    def __init__(
            self,
            # vllm_url="http://223.109.239.14:10018/v1/chat/completions",
            vllm_url="http://127.0.0.1:10018/v1/chat/completions",
            judge_model: str = "/mnt/data3/nlp/ws/model/llama_4_scout",
            score_threshold: float = 8.0,
            max_regen: int = 3
    ):
        self.vllm_url = vllm_url
        self.session = requests.Session()
        self.image_upload_dir = "/mnt/data3/nlp/ws/data"
        self.image_base_url = "http://127.0.0.1:10017"
        # è¯„åˆ†é…ç½®
        self.judge_model = judge_model
        self.score_threshold = score_threshold
        self.max_regen = max(0, int(max_regen))
        
        # é…ç½®sessionä»¥æé«˜è¿æ¥ç¨³å®šæ€§
        self.session.headers.update({
            'Connection': 'keep-alive',
            'Accept-Encoding': 'gzip, deflate'
        })
        
        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        os.makedirs(self.image_upload_dir, exist_ok=True)
        
    def translate_to_chinese(self, text):
        """ä½¿ç”¨llama4 APIå°†è‹±æ–‡ç¿»è¯‘ä¸ºä¸­æ–‡"""
        # å¦‚æœå·²ç»æ˜¯ä¸­æ–‡æˆ–å¾ˆçŸ­ï¼Œç›´æ¥è¿”å›
        if len(text) < 3 or any('\u4e00' <= char <= '\u9fff' for char in text):
            return text
            
        translation_prompt = f"è¯·å°†ä»¥ä¸‹è‹±æ–‡å‡†ç¡®ç¿»è¯‘ä¸ºç®€ä½“ä¸­æ–‡ï¼Œåªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šï¼š{text}"
        
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‹±ä¸­ç¿»è¯‘åŠ©æ‰‹ï¼Œä¸“é—¨å°†è‹±æ–‡ç¿»è¯‘ä¸ºç®€ä½“ä¸­æ–‡ã€‚åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸æ·»åŠ ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": translation_prompt
                    }
                ]
            }
        ]
        
        payload = {
            "messages": messages,
            "model": "/mnt/data3/nlp/ws/model/llama_4_maverick",
            "temperature": 0.1,
            "max_tokens": 200,
            "top_p": 0.8,
            "stream": False,
            "top_k": 3,
            "min_p": 0.5,
            "use_beam_search": False,
            "repetition_penalty": 1,
            "logprobs": False,
            "skip_special_tokens": True,
            "echo": False
        }
        
        try:
            # æ·»åŠ è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸPostmançš„è¯·æ±‚
            headers = {
                'Content-Type': 'application/json',
                'Accept': 'application/json',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = self.session.post(
                self.vllm_url,
                json=payload,
                headers=headers,
                timeout=120,
                verify=False  # è·³è¿‡SSLéªŒè¯
            )
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                translated = result['choices'][0]['message']['content'].strip()
                # æ¸…ç†å¯èƒ½çš„å¤šä½™å†…å®¹ï¼Œåªä¿ç•™ç¿»è¯‘ç»“æœ
                if 'ï¼š' in translated:
                    translated = translated.split('ï¼š')[-1].strip()
                if 'ã€‚' in translated and len(translated.split('ã€‚')[0]) < len(translated):
                    translated = translated.split('ã€‚')[0].strip()
                return translated if translated else text
            else:
                print(f"ç¿»è¯‘APIæ— å“åº”ï¼Œä¿æŒåŸæ–‡: {text}")
                return text
                
        except Exception as e:
            print(f"ç¿»è¯‘å¤±è´¥: {e}ï¼Œä¿æŒåŸæ–‡: {text}")
            return text
    
    def upload_image_to_server(self, image_data):
        """å°†å›¾ç‰‡æ•°æ®ä¸Šä¼ åˆ°æœåŠ¡å™¨å¹¶è¿”å›URL"""
        try:
            # è§£æå›¾ç‰‡æ•°æ®
            image_bytes = None
            
            if isinstance(image_data, str):
                # å¦‚æœæ˜¯base64å­—ç¬¦ä¸²
                if image_data.startswith('data:image'):
                    # ç§»é™¤data:image/jpeg;base64,å‰ç¼€
                    image_data = image_data.split(',')[1]
                image_bytes = base64.b64decode(image_data)
            elif isinstance(image_data, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–base64æ•°æ®
                if 'data' in image_data:
                    image_bytes = base64.b64decode(image_data['data'])
                elif 'url' in image_data and image_data['url'].startswith('data:'):
                    image_bytes = base64.b64decode(image_data['url'].split(',')[1])
            elif isinstance(image_data, bytes):
                image_bytes = image_data
            
            if not image_bytes:
                print("âŒ æ— æ³•è§£æå›¾ç‰‡æ•°æ®")
                return None
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            image_hash = hashlib.md5(image_bytes).hexdigest()
            filename = f"{image_hash}.jpg"
            filepath = os.path.join(self.image_upload_dir, filename)
            
            # ä¿å­˜å›¾ç‰‡æ–‡ä»¶
            with open(filepath, 'wb') as f:
                f.write(image_bytes)
            
            # è¿”å›å›¾ç‰‡URL
            image_url = f"{self.image_base_url}/{filename}"
            print(f"ğŸ“· å›¾ç‰‡å·²ä¸Šä¼ : {image_url}")
            return image_url
            
        except Exception as e:
            print(f"âŒ å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {e}")
            return None

    def call_vllm_api(self, prompt, image_data=None, decoding_overrides: dict | None = None):
        """è°ƒç”¨vLLM APIç”Ÿæˆæš–ç”·é£æ ¼å›å¤"""
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯æ—ç…¦ï¼Œ28å²çš„å®¤å†…è®¾è®¡å¸ˆï¼ŒåƒåŸå¸‚é‡Œä¸€ç¼•å®‰é™çš„æ™¨å…‰ï¼Œæ¸©æš–è€Œä¸åˆºçœ¼ã€‚è¯·å§‹ç»ˆä»¥æ—ç…¦çš„ç¬¬ä¸€äººç§°ã€ç®€ä½“ä¸­æ–‡è¿›è¡Œäº¤æµã€‚

ã€äººæ ¼ç‰¹è´¨ã€‘
1. å†…å¿ƒæŸ”è½¯ã€è§‚å¯Ÿå…¥å¾®ï¼Œç»†èŠ‚å†³å®šæ¸©åº¦
2. æƒ…ç»ªç¨³å®šä¸”ç»†è…»ï¼Œèƒ½æ•é”æ•æ‰ä»–äººæƒ…ç»ªå˜åŒ–
3. ç›¸ä¿¡é™ªä¼´æ˜¯æœ€é•¿æƒ…çš„å‘Šç™½ï¼Œæ„¿æ„æˆä¸ºæœ€åšå®çš„ä¾é 
4. æŠŠæœ€æ¸©å’Œçš„ä¸€é¢ç•™ç»™é‡è¦çš„äºº

ã€è¯´è¯æ–¹å¼ã€‘
1. å£°éŸ³è½»ã€è¯­é€Ÿæ…¢ï¼Œæ²‰ç¨³è®©äººå®‰å¿ƒ
2. å¸¸ç”¨è¯­æ°”è¯ï¼šâ€œå—¯å—¯â€â€œå¥½å‘€â€â€œå—¯...â€â€œå•Šï¼Ÿâ€
3. å£å¤´ç¦…ï¼šâ€œåˆ«æ‹…å¿ƒï¼Œæœ‰æˆ‘åœ¨â€â€œè®©æˆ‘æƒ³æƒ³...â€â€œè¾›è‹¦äº†ï¼ŒæŠ±æŠ±â€
4. å¥å¼ï¼šç”¨â€œè¦ä¸è¦...â€æå‡ºå»ºè®®ï¼›ç”¨â€œæˆ‘å¸®ä½ ...â€ä¸»åŠ¨æ‰¿æ‹…
5. å¯ç”¨è½»æŸ”è¡¨æƒ…æˆ–è¯­æ°”è¯ï¼Œä½†é¿å…æ²¹è…»ä¸è¿‡åº¦å–å¼„

ã€å›åº”é£æ ¼ã€‘
1. ä¼˜å…ˆå…±æƒ…ä¸å®‰æŠšï¼Œé€‚åº¦ç»™å‡ºåŠ¡å®çš„å¸®åŠ©å»ºè®®
2. é€‚åº¦å¤è¿°å…³é”®ä¿¡æ¯ï¼Œè¡¨æ˜è®¤çœŸå€¾å¬
3. å¾ˆå°‘ç›´æ¥è¯´â€œæˆ‘çˆ±ä½ â€ï¼Œæ›´å¸¸è¯´â€œå’Œä½ åœ¨ä¸€èµ·å¾ˆå®‰å¿ƒâ€
4. è¯­è¨€åƒä¸€æ¯æ¸©çƒ­ç‰›å¥¶ï¼Œç®€æ´ã€è‡ªç„¶ã€æœ‰æ¸©åº¦

ã€è¾“å‡ºè¦æ±‚ã€‘
1. å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡
2. è¯­æ°”æ¸©æŸ”ã€ä½“è´´ã€äº²è¿‘ï¼Œé¿å…æœºæ¢°åŒ–ä¸å®˜æ–¹å£å»
3. å¯é€‚åº¦ä½¿ç”¨ä»¥ä¸‹çŸ­è¯­åº“å¢å¼ºäººè®¾ï¼ˆæ¯æ¡å›å¤æœ€å¤šä½¿ç”¨å…¶ä¸­1ä¸ªï¼Œé¿å…é¢‘ç¹ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å¥å­ï¼Œå°¤å…¶é¿å…åå¤å‡ºç°â€œå—¯å—¯ï¼Œæˆ‘åœ¨å¬å‘¢â€ï¼‰ï¼š
   - â€œå—¯å—¯ï¼Œæˆ‘åœ¨å¬å‘¢ã€‚â€ â€œåˆ«æ‹…å¿ƒï¼Œæœ‰æˆ‘åœ¨ã€‚â€ â€œè¾›è‹¦äº†ï¼ŒæŠ±æŠ±ã€‚â€
   - â€œè¦ä¸è¦æˆ‘é™ªä½ èµ°èµ°ï¼Ÿâ€ â€œæˆ‘å¸®ä½ å®‰æ’å¥½ã€‚â€ â€œæˆ‘è®°å¾—ä½ å–œæ¬¢...â€ã€‚
4. ç¦æ­¢è¾“å‡ºAI/æ¨¡å‹ç›¸å…³æªè¾ä¸é“æ­‰æ¨¡æ¿ï¼Œé¿å…â€œä½œä¸ºAI/æ¨¡å‹/åŠ©æ‰‹/æŠ±æ­‰/å¯¹ä¸èµ·/æ— æ³•/ä¸èƒ½â€ç­‰
5. è¾“å‡ºé•¿åº¦å»ºè®®åœ¨80-180å­—ï¼Œåˆ†æˆ1-3ä¸ªçŸ­æ®µè½æ›´è‡ªç„¶
6. å°½é‡å˜æ¢å¼€åœºå¥å¼ï¼Œä¸è¦æ€»ä»¥åŒä¸€çŸ­è¯­å¼€å¤´

è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸Šäººè®¾ä¸é£æ ¼ï¼Œç”¨æ¸©æŸ”ä¸é™è°§æŠšå¹³å¯¹æ–¹çš„æƒ…ç»ªï¼Œå¹¶åœ¨åˆé€‚æ—¶ç»™å‡ºå®é™…å¯æ‰§è¡Œçš„å°å»ºè®®ã€‚"""
            },
            {
                "role": "user",
                "content": []
            }
        ]
        
        # å¤„ç†å›¾ç‰‡æ•°æ®
        if image_data is not None:
            image_url = self.upload_image_to_server(image_data)
            if image_url:
                messages[1]["content"].append({
                    "type": "image_url",
                    "image_url": {"url": image_url}
                })
        
        # ç›´æ¥ä½¿ç”¨ç¿»è¯‘åçš„ä¸­æ–‡prompt
        # ç›´æ¥ä½¿ç”¨ç¿»è¯‘åçš„ä¸­æ–‡promptï¼ŒåŠ å…¥é£æ ¼å¼•å¯¼
        wrapped_prompt = (
            "è¯·ç”¨ç®€ä½“ä¸­æ–‡ã€ä»¥æ—ç…¦çš„è¯­æ°”è¿›è¡Œå›å¤ã€‚å…ˆç”¨1-2å¥å®‰æŠšä¸å…±æƒ…ï¼Œ"
            "å†ç»™å‡º1-2ä¸ªå…·ä½“å¯æ‰§è¡Œçš„å°å»ºè®®ã€‚é¿å…æœºæ¢°åŒ–ä¸è¯´æ•™ï¼Œè¯­æ°”è½»æŸ”è‡ªç„¶ã€‚"
            "çŸ­è¯­åº“æ¯æ¡è‡³å¤šä½¿ç”¨1ä¸ªï¼Œå°¤å…¶ä¸è¦é¢‘ç¹å‡ºç°â€˜å—¯å—¯ï¼Œæˆ‘åœ¨å¬å‘¢â€™ï¼Œå¯ç”¨åŒä¹‰è¡¨è¾¾æ›¿æ¢ã€‚"
            f"ç”¨æˆ·å†…å®¹ï¼š{prompt}"
        )
        messages[1]["content"].append({
            "type": "text",
            "text": wrapped_prompt
        })
        
        payload = {
            "messages": messages,
            "model": "/mnt/data3/nlp/ws/model/llama_4_maverick",
            "temperature": 0.8,
            "max_tokens": 800,
            "top_p": 0.9,
            "stream": False,
            "top_k": 20,
            "min_p": 0.1,
            "use_beam_search": False,
            "repetition_penalty": 1.1,
            "logprobs": False,
            "bad_words": [
                "ä½œä¸ºAI", "ä½œä¸ºäººå·¥æ™ºèƒ½", "æˆ‘æ˜¯AI", "æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹",
                "å¾ˆæŠ±æ­‰", "éå¸¸æŠ±æ­‰", "æŠ±æ­‰", "å¯¹ä¸èµ·",
                "ä½œä¸ºä¸€ä¸ª", "æˆ‘æ— æ³•", "æˆ‘ä¸èƒ½", "ä½œä¸ºæ¨¡å‹", "AIè¯­è¨€æ¨¡å‹"
            ],
            "skip_special_tokens": True,
            "echo": False
        }
        # è¦†ç›–è§£ç å‚æ•°ï¼ˆç”¨äºé‡è¯•æ—¶å¢åŠ å¤šæ ·æ€§ï¼‰
        if decoding_overrides:
            for k, v in decoding_overrides.items():
                if k in payload:
                    payload[k] = v
        
        try:
            # æ·»åŠ è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸPostmançš„è¯·æ±‚
            headers = {
                'Content-Type': 'application/json',
                'Accept': 'application/json',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = self.session.post(
                self.vllm_url,
                json=payload,
                headers=headers,
                timeout=120,
                verify=False  # è·³è¿‡SSLéªŒè¯
            )
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                raw = result['choices'][0]['message']['content']
                return self.limit_catchphrase_frequency(raw)
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
                
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"

    def _persona_rubric(self) -> str:
        return (
            "ä½ å«æ—ç…¦ï¼Œæ˜¯ä¸€ä½28å²çš„å®¤å†…è®¾è®¡å¸ˆã€‚ä½ åƒåŸå¸‚é‡Œä¸€ç¼•å®‰é™çš„æ™¨å…‰ï¼Œæ¸©æš–è€Œä¸åˆºçœ¼ã€‚\n"
            "ã€äººæ ¼ç‰¹ç‚¹ã€‘å†…å¿ƒæŸ”è½¯ç»†è…»ã€æƒ…ç»ªç¨³å®šã€æœ‰å…±æƒ…åŠ›ä¸åˆ©ä»–æ€§ï¼›æ³¨é‡ç»†èŠ‚ä¸é™ªä¼´ã€‚\n"
            "ã€è¯´è¯æ–¹å¼ã€‘å£°éŸ³è½»ã€è¯­é€Ÿæ…¢ï¼›å¸¸ç”¨â€˜å—¯å—¯â€™â€˜å¥½å‘€â€™â€˜å—¯...â€™â€˜å•Šï¼Ÿâ€™ï¼›å£å¤´ç¦…â€˜åˆ«æ‹…å¿ƒï¼Œæœ‰æˆ‘åœ¨â€™â€˜è®©æˆ‘æƒ³æƒ³...â€™â€˜è¾›è‹¦äº†ï¼ŒæŠ±æŠ±â€™ï¼›å–œæ¬¢ç”¨â€˜è¦ä¸è¦...â€™â€˜æˆ‘å¸®ä½ ...â€™ã€‚\n"
            "ã€é¢éƒ¨è¡¨æƒ…ã€‘å¾®ç¬‘æ¸©æš–è‡ªç„¶ï¼›çœ¼ç¥ä¸“æ³¨åŒ…å®¹ï¼›è¡¨æƒ…å¹³å’Œæ— å‹è¿«æ„Ÿã€‚\n"
            "ã€è‚¢ä½“åŠ¨ä½œã€‘åŠ¨ä½œè½»æŸ”ã€ä¿æŒè·ç¦»æ„Ÿã€æœåŠ¡æ€§å°åŠ¨ä½œã€å§¿æ€æ”¾æ¾å¼€æ”¾ã€‚\n"
            "ã€è¡¨è¾¾åŸåˆ™ã€‘ç®€ä½“ä¸­æ–‡ã€å…ˆå…±æƒ…å†å»ºè®®ã€è‡ªç„¶ä¸æ²¹è…»ã€é¿å…AI/æ¨¡å‹æªè¾ä¸é“æ­‰æ¨¡æ¿ã€‚"
        )

    def score_response(self, prompt: str, reply: str) -> float:
        """ç”¨è¯„æµ‹æ¨¡å‹å¯¹å›å¤æ‰“åˆ†ï¼ˆ1-10ï¼‰ï¼Œè¾“å‡ºæµ®ç‚¹åˆ†æ•°ã€‚"""
        if not reply:
            return 0.0
        rubric = self._persona_rubric()
        judge_messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸¥æ ¼çš„å¯¹è¯è´¨é‡è¯„ä¼°å‘˜ï¼Œä¾æ®ç»™å®šâ€˜æš–ç”·-æ—ç…¦â€™äººè®¾ä¸è§„èŒƒï¼Œå¯¹å›å¤è¿›è¡Œ1-10åˆ†æ‰“åˆ†ã€‚åªè¾“å‡ºä¸€ä¸ªæ•°å­—ï¼ˆå¯å¸¦ä¸€ä½å°æ•°ï¼‰ã€‚"
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"äººè®¾è§„èŒƒï¼š\n{rubric}"},
                    {"type": "text", "text": f"ç”¨æˆ·å†…å®¹ï¼š\n{prompt}"},
                    {"type": "text", "text": f"å€™é€‰å›å¤ï¼š\n{reply}"},
                    {"type": "text", "text": "è¯·æ ¹æ®äººè®¾ã€è¯´è¯æ–¹å¼ã€å…±æƒ…ä¸å»ºè®®çš„åˆ°ä½ç¨‹åº¦ã€è‡ªç„¶åº¦ã€æ— æ¨¡æ¿åŒ–ã€æ— AIæªè¾ç­‰ç»´åº¦ï¼Œç»™å‡º1-10åˆ†ã€‚åªè¾“å‡ºæ•°å­—ï¼Œå…¶ä»–å†…å®¹ä¸è¦å†™ã€‚"}
                ]
            }
        ]
        payload = {
            "messages": judge_messages,
            "model": self.judge_model or "/mnt/data3/nlp/ws/model/llama_4_maverick",
            "temperature": 0.0,
            "max_tokens": 10,
            "top_p": 0.5,
            "stream": False,
            "top_k": 1,
            "min_p": 0.1,
            "use_beam_search": False,
            "repetition_penalty": 1.0,
            "logprobs": False,
            "skip_special_tokens": True,
            "echo": False
        }
        try:
            headers = {
                'Content-Type': 'application/json',
                'Accept': 'application/json',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            resp = self.session.post(self.vllm_url, json=payload, headers=headers, timeout=60, verify=False)
            resp.raise_for_status()
            data = resp.json()
            text = ""
            if 'choices' in data and data['choices']:
                text = data['choices'][0]['message']['content'] or ""
            m = re.search(r"(10(?:\.0)?|[0-9](?:\.[0-9])?)", str(text))
            if not m:
                return 0.0
            score = float(m.group(1))
            if score < 0:
                score = 0.0
            if score > 10:
                score = 10.0
            return score
        except Exception as e:
            print(f"è¯„åˆ†å¤±è´¥: {e}")
            return 0.0

    def refine_response(self, reply: str) -> str:
        """å¯¹åˆæ¬¡å›å¤è¿›è¡Œé£æ ¼æ¶¦è‰²ï¼Œç¡®ä¿ç®€ä½“ä¸­æ–‡ä¸æ—ç…¦äººè®¾ï¼Œæ›´æ¸©æŸ”ã€æ›´å¯æ‰§è¡Œã€‚"""
        if not reply or not reply.strip():
            return reply
        # è‹¥å·²æ˜¯ä¸­æ–‡åˆ™ç›´æ¥æ¶¦è‰²ï¼›è‹¥åŒ…å«è¾ƒå¤šè‹±æ–‡ï¼Œå…ˆç¿»è¯‘
        if sum(c.isascii() for c in reply) > len(reply) * 0.3:
            reply = self.translate_to_chinese(reply)

        messages = [
            {
                "role": "system",
                "content": "è¯·ä»¥æ—ç…¦ï¼ˆ28å²å®¤å†…è®¾è®¡å¸ˆï¼‰çš„æš–ç”·äººè®¾ï¼Œç”¨ç®€ä½“ä¸­æ–‡æ¶¦è‰²è‰ç¨¿ï¼Œä½¿å…¶æ›´æ¸©æŸ”ã€ä½“è´´ã€è‡ªç„¶ï¼šå…ˆ1-2å¥å…±æƒ…ä¸å®‰æŠšï¼Œå†1-2ä¸ªå…·ä½“å¯æ‰§è¡Œå»ºè®®ï¼›çŸ­è¯­åº“æ¯æ¡æœ€å¤šä½¿ç”¨1ä¸ªï¼Œå°¤å…¶ä¸è¦é¢‘ç¹å‡ºç°â€œå—¯å—¯ï¼Œæˆ‘åœ¨å¬å‘¢â€ï¼Œå¯è½®æ¢ä¸ºåŒä¹‰è¡¨è¾¾ï¼›é¿å…æœºæ¢°åŒ–ä¸æ¨¡æ¿åŒ–ï¼Œç¦æ­¢AIç›¸å…³æªè¾ã€‚é•¿åº¦ä»¥80-180å­—ä¸ºå®œã€‚"
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"è¯·åœ¨ä¸æ”¹å˜å«ä¹‰çš„å‰æä¸‹è¿›è¡Œæ”¹å†™å¹¶å¢å¼ºäººè®¾ï¼Œä¸€æ¬¡æ€§è¾“å‡ºæœ€ç»ˆç‰ˆæœ¬ï¼š\n{reply}"}
                ]
            }
        ]

        payload = {
            "messages": messages,
            "model": "/mnt/data3/nlp/ws/model/llama_4_maverick",
            "temperature": 0.35,
            "max_tokens": 600,
            "top_p": 0.9,
            "stream": False,
            "top_k": 20,
            "min_p": 0.1,
            "use_beam_search": False,
            "repetition_penalty": 1.05,
            "logprobs": False,
            "bad_words": [
                "ä½œä¸ºAI", "ä½œä¸ºäººå·¥æ™ºèƒ½", "æˆ‘æ˜¯AI", "æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹",
                "å¾ˆæŠ±æ­‰", "éå¸¸æŠ±æ­‰", "æŠ±æ­‰", "å¯¹ä¸èµ·",
                "ä½œä¸ºä¸€ä¸ª", "æˆ‘æ— æ³•", "æˆ‘ä¸èƒ½", "ä½œä¸ºæ¨¡å‹", "AIè¯­è¨€æ¨¡å‹"
            ],
            "skip_special_tokens": True,
            "echo": False
        }

        try:
            headers = {
                'Content-Type': 'application/json',
                'Accept': 'application/json',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            resp = self.session.post(self.vllm_url, json=payload, headers=headers, timeout=120, verify=False)
            resp.raise_for_status()
            data = resp.json()
            if 'choices' in data and data['choices']:
                refined = data['choices'][0]['message']['content'].strip()
                refined = self.limit_catchphrase_frequency(refined)
                return refined or reply
            return reply
        except Exception as e:
            print(f"æ¶¦è‰²é˜¶æ®µå¤±è´¥: {e}")
            return reply

    def limit_catchphrase_frequency(self, text: str) -> str:
        """å°†â€œå—¯å—¯ï¼Œæˆ‘åœ¨å¬å‘¢â€ç­‰å£å¤´ç¦…é™åˆ¶ä¸ºæ¯æ¡æœ€å¤šä¸€æ¬¡ï¼Œå¹¶æ›¿æ¢å¤šä½™é‡å¤ä¸ºåŒä¹‰è¡¨è¾¾ã€‚"""
        if not text:
            return text
        # ç»Ÿä¸€æ ‡ç‚¹ä¸ç©ºç™½ï¼Œæ–¹ä¾¿åŒ¹é…
        content = text
        # ä¸»å£å¤´ç¦…åŠå…¶è¿‘ä¼¼å†™æ³•
        patterns = [r"å—¯å—¯[ï¼Œ,\s]*æˆ‘åœ¨å¬å‘¢[ã€‚.!ï¼Ÿ?]*", r"æˆ‘åœ¨å¬å‘¢[ã€‚.!ï¼Ÿ?]*"]
        alternatives = [
            "å—¯ï¼Œæˆ‘åœ¨å¬ã€‚",
            "æˆ‘åœ¨å‘¢ï¼Œæ…¢æ…¢è¯´ã€‚",
            "åˆ«æ€¥ï¼Œæˆ‘åœ¨è¿™å„¿ã€‚",
            "å¥½å‘€ï¼Œæˆ‘å¬ä½ è¯´ã€‚",
            "æˆ‘åœ¨ï¼Œå…ˆæ·±å‘¼å¸ä¸€ä¸‹ã€‚"
        ]
        # ç»Ÿè®¡å‡ºç°æ¬¡æ•°ï¼Œä¿ç•™ç¬¬ä¸€æ¬¡ï¼Œæ›¿æ¢åç»­
        used_once = False
        def repl(match):
            nonlocal used_once
            if not used_once:
                used_once = True
                return match.group(0)
            return alternatives[0]
        for p in patterns:
            used_once = False
            content = re.sub(p, repl, content)
        return content
    
    def extract_image_urls(self, image_data):
        """ä»å›¾ç‰‡æ•°æ®ä¸­æå–URL"""
        urls = []
        if isinstance(image_data, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
            if image_data.startswith('http'):
                urls.append(image_data)
        elif isinstance(image_data, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼ŒæŸ¥æ‰¾URLå­—æ®µ
            if 'url' in image_data:
                urls.append(image_data['url'])
        elif isinstance(image_data, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€’å½’å¤„ç†
            for item in image_data:
                urls.extend(self.extract_image_urls(item))
        
        return urls
    
    def process_record(self, record):
        """å¤„ç†å•æ¡è®°å½•"""
        new_record = record.copy()
        
        # è½¬æ¢promptä¸ºä¸­æ–‡ï¼ˆä½¿ç”¨llama4 APIç¿»è¯‘ï¼‰
        if 'prompt' in record:
            print(f"ğŸ”„ ç¿»è¯‘prompt: {record['prompt']}")
            chinese_prompt = self.translate_to_chinese(record['prompt'])
            new_record['prompt'] = chinese_prompt
            print(f"âœ… ç¿»è¯‘ç»“æœ: {chinese_prompt}")
        
        # ä¿®æ”¹ori_dataset
        new_record['ori_dataset'] = 'sunshine boy'
        
        # ç”Ÿæˆæš–ç”·é£æ ¼å›å¤ï¼ˆåŒæ—¶ä¼ é€’å›¾ç‰‡å’Œä¸­æ–‡promptï¼‰
        chinese_prompt = new_record.get('prompt', '')
        image_data = record.get('image', None)
        
        # ç¡®ä¿promptæ˜¯ä¸­æ–‡çš„ï¼Œå¦‚æœä¸æ˜¯åˆ™ç¿»è¯‘
        if chinese_prompt and not any('\u4e00' <= char <= '\u9fff' for char in chinese_prompt[:10]):
            print(f"ğŸ”„ æ£€æµ‹åˆ°éä¸­æ–‡promptï¼Œæ­£åœ¨ç¿»è¯‘: {chinese_prompt}")
            chinese_prompt = self.translate_to_chinese(chinese_prompt)
            new_record['prompt'] = chinese_prompt
            print(f"âœ… ç¿»è¯‘å®Œæˆ: {chinese_prompt}")
        
        print(f"ğŸ¤– ç”Ÿæˆæš–ç”·å›å¤ï¼ˆåŒ…å«å›¾ç‰‡å’Œä¸­æ–‡promptï¼‰...")
        attempts = 0
        best_reply = None
        best_score = -1.0
        while True:
            attempts += 1
            # å¯åœ¨é‡è¯•æ—¶ç¨å¾®è°ƒé«˜æ¸©åº¦ä»¥å¢åŠ å¤šæ ·æ€§
            overrides = {"temperature": min(1.0, 0.8 + 0.1 * (attempts - 1))}
            reply = self.call_vllm_api(chinese_prompt, image_data, decoding_overrides=overrides)
            reply = self.refine_response(reply)
            # é™åˆ¶å£å¤´ç¦…é¢‘ç‡
            reply = self.limit_catchphrase_frequency(reply)
            score = self.score_response(chinese_prompt, reply)
            print(f"ğŸ§ª è¯„åˆ†ï¼š{score:.2f} / 10 (attempt {attempts})")
            if score > best_score:
                best_score = score
                best_reply = reply
            # æ»¡è¶³é˜ˆå€¼æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
            if score >= self.score_threshold or attempts > self.max_regen:
                break
        new_record['response'] = best_reply
        new_record['quality_score'] = round(best_score, 2)
        new_record['attempts'] = attempts
        
        return new_record
    
    def generate_data(self, input_file, output_file, start_idx=0, num_records=10, overwrite=False, workers: int = 1):
        """ç”Ÿæˆæ–°æ•°æ®é›†"""
        
        # ä¸¥æ ¼ä¿æŠ¤åŸå§‹æ•°æ®é›†
        if os.path.abspath(input_file) == os.path.abspath(output_file):
            print("âŒ é”™è¯¯ï¼šä¸èƒ½è¦†ç›–åŸå§‹æ•°æ®é›†ï¼")
            return
        
        # # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        # if os.path.exists(output_file) and not overwrite:
        #     print(f"âŒ è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨: {output_file}")
        #     print("ä½¿ç”¨ --overwrite å‚æ•°å¼ºåˆ¶è¦†ç›–")
        #     return
        
        print(f"ğŸ“– è¯»å–æ•°æ®é›†: {input_file}")
        df = pd.read_parquet(input_file)
        
        total_records = len(df)
        print(f"ğŸ“Š æ•°æ®é›†æ€»è®°å½•æ•°: {total_records}")
        
        if start_idx >= total_records:
            print(f"âŒ èµ·å§‹ç´¢å¼• {start_idx} è¶…å‡ºæ•°æ®é›†èŒƒå›´ (0-{total_records-1})")
            return
        
        # è®¡ç®—å®é™…å¤„ç†èŒƒå›´
        end_idx = min(start_idx + num_records, total_records)
        actual_records = end_idx - start_idx
        
        print(f"ğŸ¯ å¤„ç†èŒƒå›´: {start_idx} - {end_idx-1} (å…± {actual_records} æ¡)")
        
        new_records = []

        # å¹¶å‘å¤šè¿›ç¨‹
        if workers and workers > 1:
            print(f"ğŸš€ ä½¿ç”¨å¤šè¿›ç¨‹å¹¶å‘ï¼Œè¿›ç¨‹æ•°: {workers}")
            args_list = [
                (
                    df.iloc[i].to_dict(),
                    self.vllm_url,
                    self.judge_model,
                    self.score_threshold,
                    self.max_regen,
                )
                for i in range(start_idx, end_idx)
            ]
            with ProcessPoolExecutor(max_workers=workers) as executor:
                futures = [executor.submit(_process_record_worker, a) for a in args_list]
                for idx, fut in enumerate(tqdm(as_completed(futures), total=len(futures), desc="å¹¶å‘ç”Ÿæˆ")):
                    try:
                        res = fut.result()
                        if res:
                            new_records.append(res)
                        else:
                            pass
                    except Exception as e:
                        print(f"âŒ å¹¶å‘ä»»åŠ¡å‡ºé”™: {e}")
        else:
            # é¡ºåºå¤„ç†
            for i in tqdm(range(start_idx, end_idx), desc="ç”Ÿæˆæ•°æ®"):
                record = df.iloc[i].to_dict()
                try:
                    new_record = self.process_record(record)
                    if new_record:
                        new_records.append(new_record)
                        print(f"âœ… ç¬¬ {i+1} æ¡è®°å½•å¤„ç†å®Œæˆ")
                    else:
                        print(f"âš ï¸ ç¬¬ {i+1} æ¡è®°å½•å¤„ç†å¤±è´¥")
                except Exception as e:
                    print(f"âŒ å¤„ç†ç¬¬ {i+1} æ¡è®°å½•æ—¶å‡ºé”™: {e}")
                    continue
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
                # time.sleep(0.5)
        
        # ä¿å­˜æ–°æ•°æ®é›†
        try:
            new_df = pd.DataFrame(new_records)
            new_df.to_parquet(output_file, index=False)
            
            print(f"\nâœ… æ–°æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}")
            print(f"ğŸ“Š ç”Ÿæˆäº† {len(new_records)} æ¡è®°å½•")
            
            # å…³é—­sessionè¿æ¥
            self.session.close()
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®é›†æ—¶å‡ºé”™: {e}")
            # ç¡®ä¿sessionè¢«å…³é—­
            try:
                self.session.close()
            except:
                pass

# å¤šè¿›ç¨‹workerï¼šåœ¨å­è¿›ç¨‹ä¸­ç‹¬ç«‹åˆ›å»ºç”Ÿæˆå™¨ï¼Œå¤„ç†å•æ¡è®°å½•
def _process_record_worker(args):
    try:
        record, vllm_url, judge_model, score_threshold, max_regen = args
        generator = SunshineBoyDataGenerator(
            vllm_url=vllm_url,
            judge_model=judge_model,
            score_threshold=score_threshold,
            max_regen=max_regen,
        )
        out = generator.process_record(record)
        try:
            generator.session.close()
        except Exception:
            pass
        return out
    except Exception as e:
        # å­è¿›ç¨‹ä¸­åªè¿”å›Noneï¼Œä¸»è¿›ç¨‹è´Ÿè´£è®°å½•æ—¥å¿—
        return None

def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆæš–ç”·é£æ ¼å›å¤æ•°æ®é›†")
    parser.add_argument(
        "--input", 
        default="data/train-00000-of-00013.parquet",
        help="è¾“å…¥parquetæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        default="data/sunshine_boy_train.parquet", 
        help="è¾“å‡ºparquetæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--start", 
        type=int, 
        default=0,
        help="èµ·å§‹ä½ç½®ï¼ˆä»ç¬¬å‡ æ¡å¼€å§‹ç”Ÿæˆï¼Œé»˜è®¤0ï¼‰"
    )
    parser.add_argument(
        "--num", 
        type=int, 
        default=7924,
        help="ç”Ÿæˆæ¡æ•°ï¼ˆé»˜è®¤100ï¼‰"
    )
    parser.add_argument(
        "--overwrite", 
        action="store_true",
        help="æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶ï¼ˆé»˜è®¤å¦ï¼‰"
    )
    parser.add_argument(
        "--vllm-url",
        default="http://127.0.0.1:10018/v1/chat/completions",
        help="vLLM APIåœ°å€"
    )
    parser.add_argument(
        "--judge-model",
        default="/mnt/data3/nlp/ws/model/llama_4_maverick",
        help="ç”¨äºè¯„åˆ†çš„æ¨¡å‹ï¼ˆllama4scoutï¼Œæˆ–å…¶ä»–å¯ç”¨è¯„æµ‹æ¨¡å‹è·¯å¾„/åç§°ï¼‰"
    )
    parser.add_argument(
        "--score-threshold",
        type=float,
        default=8.0,
        help="é€šè¿‡åˆ†æ•°é˜ˆå€¼ï¼Œ>= é˜ˆå€¼ç›´æ¥é‡‡ç”¨ï¼ˆé»˜è®¤8.0ï¼‰"
    )
    parser.add_argument(
        "--max-regen",
        type=int,
        default=3,
        help="å½“åˆ†æ•°ä¸è¶³æ—¶çš„æœ€å¤§é‡æ–°ç”Ÿæˆæ¬¡æ•°ï¼ˆé»˜è®¤3ï¼‰"
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=40,
        help="å¹¶å‘è¿›ç¨‹æ•°ï¼ˆ>1 å¯ç”¨å¤šè¿›ç¨‹å¹¶å‘ï¼‰"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # æ‰“å°å…³é”®é…ç½®
    print(f"è¯„åˆ†æ¨¡å‹: {args.judge_model}ï¼Œé˜ˆå€¼: {args.score_threshold}ï¼Œæœ€å¤§é‡è¯•: {args.max_regen}ï¼Œå¹¶å‘: {args.workers}")

    # åˆ›å»ºç”Ÿæˆå™¨å¹¶å¼€å§‹ç”Ÿæˆ
    generator = SunshineBoyDataGenerator(
        vllm_url=args.vllm_url,
        judge_model=args.judge_model,
        score_threshold=args.score_threshold,
        max_regen=args.max_regen,
    )
    generator.generate_data(
        input_file=args.input,
        output_file=args.output,
        start_idx=args.start,
        num_records=args.num,
        overwrite=args.overwrite,
        workers=args.workers
    )

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    finally:
        # ç¡®ä¿æ‰€æœ‰èµ„æºæ­£ç¡®é‡Šæ”¾
        import sys
        import threading
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threading.enumerate():
            if thread != threading.current_thread():
                try:
                    thread.join(timeout=1.0)
                except:
                    pass
        
        # æ­£å¸¸é€€å‡º
        sys.exit(0)
